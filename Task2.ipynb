{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dist_sim_data.txt',\n",
       " 'EN-wform.w.2.ppmi.svd.500.rcv_vocab.txt',\n",
       " 'EN_syn_verb.txt',\n",
       " 'GoogleNews-vectors-rcv_vocab.txt',\n",
       " 'SAT-package-V3.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lundazi</td>\n",
       "      <td>0.106934</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>-0.016846</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>-0.196289</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273438</td>\n",
       "      <td>-0.062012</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.072754</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>-0.347656</td>\n",
       "      <td>-0.055908</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.196289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eket</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.017944</td>\n",
       "      <td>-0.082520</td>\n",
       "      <td>-0.031128</td>\n",
       "      <td>-0.143555</td>\n",
       "      <td>-0.292969</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>-0.229492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>0.165039</td>\n",
       "      <td>-0.384766</td>\n",
       "      <td>-0.433594</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.460938</td>\n",
       "      <td>-0.099121</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>-0.318359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asir</td>\n",
       "      <td>-0.073242</td>\n",
       "      <td>0.103027</td>\n",
       "      <td>-0.175781</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>-0.188477</td>\n",
       "      <td>-0.333984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180664</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.049805</td>\n",
       "      <td>-0.249023</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>-0.128906</td>\n",
       "      <td>-0.101074</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simha</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.116211</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>-0.554688</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>-0.124512</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.122559</td>\n",
       "      <td>-0.155273</td>\n",
       "      <td>-0.123535</td>\n",
       "      <td>-0.318359</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.367188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HRCP</td>\n",
       "      <td>-0.316406</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.158203</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>-0.119629</td>\n",
       "      <td>-0.134766</td>\n",
       "      <td>0.142578</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>-0.215820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>-0.018677</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>-0.194336</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>-0.063477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0  Lundazi  0.106934  0.144531 -0.081543  0.111816 -0.016846 -0.075684   \n",
       "1     Eket -0.250000 -0.017944 -0.082520 -0.031128 -0.143555 -0.292969   \n",
       "2     Asir -0.073242  0.103027 -0.175781  0.102539  0.283203  0.080566   \n",
       "3    Simha  0.088379  0.116211 -0.137695  0.121582  0.129883 -0.554688   \n",
       "4     HRCP -0.316406  0.023438  0.158203  0.034180 -0.119629 -0.134766   \n",
       "\n",
       "        7         8         9    ...       291       292       293       294  \\\n",
       "0 -0.196289  0.040283 -0.359375  ... -0.273438 -0.062012 -0.152344 -0.072754   \n",
       "1  0.012756  0.154297 -0.229492  ... -0.051025  0.165039 -0.384766 -0.433594   \n",
       "2  0.023560 -0.188477 -0.333984  ... -0.180664 -0.115234  0.220703 -0.049805   \n",
       "3  0.302734 -0.124512  0.002457  ... -0.132812  0.140625 -0.267578 -0.122559   \n",
       "4  0.142578  0.029053 -0.215820  ...  0.074219  0.011902  0.008606 -0.018677   \n",
       "\n",
       "        295       296       297       298       299       300  \n",
       "0 -0.129883  0.052490 -0.347656 -0.055908  0.056152  0.196289  \n",
       "1 -0.310547  0.171875 -0.460938 -0.099121 -0.120605 -0.318359  \n",
       "2 -0.249023  0.542969 -0.128906 -0.101074  0.167969  0.437500  \n",
       "3 -0.155273 -0.123535 -0.318359  0.179688  0.146484  0.367188  \n",
       "4 -0.013428  0.289062 -0.194336  0.093262  0.006927 -0.063477  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_vec_df = pd.read_csv(os.path.join('data','GoogleNews-vectors-rcv_vocab.txt'), sep=' ', header=None)\n",
    "google_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140922"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_words = list(google_vec_df[0])\n",
    "google_word_dict = {k:v for v, k in enumerate(google_words)}\n",
    "len(google_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140922, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_vecs = google_vec_df.drop(0, axis=1).values\n",
    "google_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neo-classic</td>\n",
       "      <td>0.183098</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.176383</td>\n",
       "      <td>-0.053295</td>\n",
       "      <td>-0.055520</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>-0.133636</td>\n",
       "      <td>0.092237</td>\n",
       "      <td>-0.094436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.036292</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.027492</td>\n",
       "      <td>-0.009265</td>\n",
       "      <td>-0.052609</td>\n",
       "      <td>-0.044142</td>\n",
       "      <td>-0.059494</td>\n",
       "      <td>0.012797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auberge</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.115123</td>\n",
       "      <td>0.056515</td>\n",
       "      <td>-0.142405</td>\n",
       "      <td>0.116539</td>\n",
       "      <td>-0.062118</td>\n",
       "      <td>0.135252</td>\n",
       "      <td>-0.078248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.027234</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.024726</td>\n",
       "      <td>-0.017699</td>\n",
       "      <td>-0.014483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deeps</td>\n",
       "      <td>0.284431</td>\n",
       "      <td>0.153209</td>\n",
       "      <td>0.247658</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>-0.218465</td>\n",
       "      <td>0.113874</td>\n",
       "      <td>-0.183892</td>\n",
       "      <td>0.058796</td>\n",
       "      <td>-0.098555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.063476</td>\n",
       "      <td>-0.023179</td>\n",
       "      <td>-0.047171</td>\n",
       "      <td>-0.061298</td>\n",
       "      <td>-0.054737</td>\n",
       "      <td>-0.041229</td>\n",
       "      <td>0.038749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-2007</td>\n",
       "      <td>0.160917</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.139675</td>\n",
       "      <td>0.033443</td>\n",
       "      <td>0.131233</td>\n",
       "      <td>-0.163524</td>\n",
       "      <td>0.094085</td>\n",
       "      <td>-0.220436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000998</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>-0.032469</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.019737</td>\n",
       "      <td>-0.016588</td>\n",
       "      <td>-0.034730</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.037919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refectory</td>\n",
       "      <td>0.278820</td>\n",
       "      <td>0.083047</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>-0.244677</td>\n",
       "      <td>0.088986</td>\n",
       "      <td>-0.088450</td>\n",
       "      <td>0.180136</td>\n",
       "      <td>0.123281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.037627</td>\n",
       "      <td>-0.040274</td>\n",
       "      <td>-0.009409</td>\n",
       "      <td>-0.020078</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.027034</td>\n",
       "      <td>-0.007744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0  neo-classic  0.183098  0.129868  0.176383 -0.053295 -0.055520  0.043304   \n",
       "1      auberge  0.187866  0.017577  0.115123  0.056515 -0.142405  0.116539   \n",
       "2        deeps  0.284431  0.153209  0.247658  0.010080 -0.218465  0.113874   \n",
       "3    1997-2007  0.160917  0.017448  0.272126  0.139675  0.033443  0.131233   \n",
       "4    refectory  0.278820  0.083047  0.156682  0.047539 -0.244677  0.088986   \n",
       "\n",
       "        7         8         9    ...       491       492       493       494  \\\n",
       "0 -0.133636  0.092237 -0.094436  ...  0.014659  0.001169  0.036292 -0.008851   \n",
       "1 -0.062118  0.135252 -0.078248  ... -0.009394  0.013320  0.001646  0.027234   \n",
       "2 -0.183892  0.058796 -0.098555  ...  0.016969  0.034882 -0.005492 -0.063476   \n",
       "3 -0.163524  0.094085 -0.220436  ... -0.000998  0.061768 -0.032469 -0.010853   \n",
       "4 -0.088450  0.180136  0.123281  ... -0.006584 -0.037627 -0.040274 -0.009409   \n",
       "\n",
       "        495       496       497       498       499       500  \n",
       "0  0.027492 -0.009265 -0.052609 -0.044142 -0.059494  0.012797  \n",
       "1  0.011830  0.013212  0.007839  0.024726 -0.017699 -0.014483  \n",
       "2 -0.023179 -0.047171 -0.061298 -0.054737 -0.041229  0.038749  \n",
       "3 -0.019737 -0.016588 -0.034730 -0.011669  0.017729  0.037919  \n",
       "4 -0.020078 -0.003393  0.025949 -0.011941 -0.027034 -0.007744  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_df = pd.read_csv(os.path.join('data','EN-wform.w.2.ppmi.svd.500.rcv_vocab.txt'), header=None, sep=' ', quoting=csv.QUOTE_NONE)\n",
    "ppmi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65362"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_words = ppmi_df[0].values.astype(str)\n",
    "ppmi_word_dict = {k: v for v, k in enumerate(ppmi_words)}\n",
    "len(ppmi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65362, 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_vecs = ppmi_df.drop(0, axis=1).values\n",
    "ppmi_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_get_dist(word1, word2, dist_func):\n",
    "    if word1 not in google_word_dict or word2 not in google_word_dict:\n",
    "        return np.inf\n",
    "    idx1 = google_word_dict[word1]\n",
    "    idx2 = google_word_dict[word2]\n",
    "    return dist_func(google_vecs[idx1], google_vecs[idx2])\n",
    "\n",
    "def ppmi_get_dist(word1, word2, dist_func):\n",
    "    word1 = word1.replace('_', '-')\n",
    "    word2 = word2.replace('_', '-')\n",
    "    if word1 not in ppmi_word_dict or word2 not in ppmi_word_dict:\n",
    "        return np.inf\n",
    "    idx1 = ppmi_word_dict[word1]\n",
    "    idx2 = ppmi_word_dict[word2]\n",
    "    return dist_func(ppmi_vecs[idx1], ppmi_vecs[idx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in the original synonym data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.word</th>\n",
       "      <th>Answer.suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_interpret</td>\n",
       "      <td>to_clarify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to_interpret</td>\n",
       "      <td>to_explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to_interpret</td>\n",
       "      <td>to_explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to_interpret</td>\n",
       "      <td>to_understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to_interpret</td>\n",
       "      <td>to_clarify</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.word Answer.suggestion\n",
       "0  to_interpret        to_clarify\n",
       "1  to_interpret        to_explain\n",
       "2  to_interpret        to_explain\n",
       "3  to_interpret     to_understand\n",
       "4  to_interpret        to_clarify"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_dict = defaultdict(set)\n",
    "syn_verb = pd.read_csv(os.path.join('data','EN_syn_verb.txt'), sep='\\t')\n",
    "syn_verb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove the leading 'to_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.word</th>\n",
       "      <th>Answer.suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interpret</td>\n",
       "      <td>clarify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interpret</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interpret</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interpret</td>\n",
       "      <td>understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interpret</td>\n",
       "      <td>clarify</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Input.word Answer.suggestion\n",
       "0  interpret           clarify\n",
       "1  interpret           explain\n",
       "2  interpret           explain\n",
       "3  interpret        understand\n",
       "4  interpret           clarify"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_verb = syn_verb[syn_verb['Answer.suggestion'] != '0'].applymap(lambda word: word.split('_', 1)[1])\n",
    "syn_verb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove synonym pairs which have out-of-voc words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in syn_verb.iterrows():\n",
    "    word1 = row['Input.word']\n",
    "    word2 = row['Answer.suggestion']\n",
    "    if word1 not in google_word_dict or word1.replace('_', '-') not in ppmi_word_dict:\n",
    "        continue\n",
    "    if word2 not in google_word_dict or word2.replace('_', '-') not in ppmi_word_dict:\n",
    "        continue\n",
    "    syn_dict[word1].add(word2)\n",
    "    syn_dict[word2].add(word1)\n",
    "question_word_set = set(syn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "question_set = []\n",
    "columns = ['given_word', 'choice1', 'choice2', 'choice3', 'choice4', 'choice5', 'correct_answer']\n",
    "\n",
    "for i in range(1000):\n",
    "    given_word = random.sample(question_word_set, 1)[0]\n",
    "    answer = random.sample(syn_dict[given_word], 1)[0]\n",
    "    choices = random.sample(question_word_set.difference(syn_dict[given_word]).difference({given_word}), 4)\n",
    "    choices.append(answer)\n",
    "    random.shuffle(choices)\n",
    "    question = [given_word, *choices, answer]\n",
    "    question_set.append(question)\n",
    "len(syn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(question_set, columns = columns)\n",
    "dataset.to_csv('synonym_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the dataset generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_word</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>choice3</th>\n",
       "      <th>choice4</th>\n",
       "      <th>choice5</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blink</td>\n",
       "      <td>whack</td>\n",
       "      <td>document</td>\n",
       "      <td>accomplish</td>\n",
       "      <td>wink</td>\n",
       "      <td>reveal</td>\n",
       "      <td>wink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phrase</td>\n",
       "      <td>study</td>\n",
       "      <td>term</td>\n",
       "      <td>proof</td>\n",
       "      <td>toil</td>\n",
       "      <td>categorize</td>\n",
       "      <td>term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dye</td>\n",
       "      <td>ink</td>\n",
       "      <td>worsen</td>\n",
       "      <td>edit</td>\n",
       "      <td>determine</td>\n",
       "      <td>organize</td>\n",
       "      <td>ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>travel</td>\n",
       "      <td>journey</td>\n",
       "      <td>attack</td>\n",
       "      <td>designate</td>\n",
       "      <td>hold</td>\n",
       "      <td>engrave</td>\n",
       "      <td>journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>devolve</td>\n",
       "      <td>transfer</td>\n",
       "      <td>protrude</td>\n",
       "      <td>criticize</td>\n",
       "      <td>slam</td>\n",
       "      <td>resonate</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  given_word   choice1   choice2     choice3    choice4     choice5  \\\n",
       "0      blink     whack  document  accomplish       wink      reveal   \n",
       "1     phrase     study      term       proof       toil  categorize   \n",
       "2        dye       ink    worsen        edit  determine    organize   \n",
       "3     travel   journey    attack   designate       hold     engrave   \n",
       "4    devolve  transfer  protrude   criticize       slam    resonate   \n",
       "\n",
       "  correct_answer  \n",
       "0           wink  \n",
       "1           term  \n",
       "2            ink  \n",
       "3        journey  \n",
       "4       transfer  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the dataset back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dataset = pd.read_csv('synonym_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>given_word</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>choice3</th>\n",
       "      <th>choice4</th>\n",
       "      <th>choice5</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>blink</td>\n",
       "      <td>whack</td>\n",
       "      <td>document</td>\n",
       "      <td>accomplish</td>\n",
       "      <td>wink</td>\n",
       "      <td>reveal</td>\n",
       "      <td>wink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>phrase</td>\n",
       "      <td>study</td>\n",
       "      <td>term</td>\n",
       "      <td>proof</td>\n",
       "      <td>toil</td>\n",
       "      <td>categorize</td>\n",
       "      <td>term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dye</td>\n",
       "      <td>ink</td>\n",
       "      <td>worsen</td>\n",
       "      <td>edit</td>\n",
       "      <td>determine</td>\n",
       "      <td>organize</td>\n",
       "      <td>ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>travel</td>\n",
       "      <td>journey</td>\n",
       "      <td>attack</td>\n",
       "      <td>designate</td>\n",
       "      <td>hold</td>\n",
       "      <td>engrave</td>\n",
       "      <td>journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>devolve</td>\n",
       "      <td>transfer</td>\n",
       "      <td>protrude</td>\n",
       "      <td>criticize</td>\n",
       "      <td>slam</td>\n",
       "      <td>resonate</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 given_word   choice1   choice2     choice3    choice4  \\\n",
       "0           0      blink     whack  document  accomplish       wink   \n",
       "1           1     phrase     study      term       proof       toil   \n",
       "2           2        dye       ink    worsen        edit  determine   \n",
       "3           3     travel   journey    attack   designate       hold   \n",
       "4           4    devolve  transfer  protrude   criticize       slam   \n",
       "\n",
       "      choice5 correct_answer  \n",
       "0      reveal           wink  \n",
       "1  categorize           term  \n",
       "2    organize            ink  \n",
       "3     engrave        journey  \n",
       "4    resonate       transfer  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the accuracy of both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google's accuracy on the dataset:           0.680 using cosine, 0.532 using euclidean\n",
      "Classic Approach's accuracy on the dataset: 0.525 using cosine, 0.525 using euclidean\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean\n",
    "google_cosine_count, google_euclidean_count, ppmi_cosine_count, ppmi_euclidean_count = 0, 0, 0, 0\n",
    "# google_out_of_v_count, ppmi_out_of_v_count = 0, 0\n",
    "for index, row in synonym_dataset.iterrows():\n",
    "    word = row['given_word']\n",
    "    choices = [row['choice' + num] for num in list('12345')]\n",
    "    correct_answer = row['correct_answer']\n",
    "    \n",
    "    google_cosine_dists = [google_get_dist(word, candidate, cosine) for candidate in choices]\n",
    "#     if any([dist == np.inf for dist in google_cosine_dists]):\n",
    "#         google_out_of_v_count += 1\n",
    "#     else:\n",
    "    google_cosine_answer = choices[np.argmin(google_cosine_dists)]\n",
    "    if google_cosine_answer == correct_answer:\n",
    "        google_cosine_count += 1\n",
    "    google_euclidean_dists = [google_get_dist(word, candidate, euclidean) for candidate in choices]\n",
    "    google_euclidean_answer = choices[np.argmin(google_euclidean_dists)]\n",
    "    if google_euclidean_answer == correct_answer:\n",
    "        google_euclidean_count += 1\n",
    "    \n",
    "    ppmi_cosine_dists = [ppmi_get_dist(word, candidate, cosine) for candidate in choices]\n",
    "#     if any([dist == np.inf for dist in ppmi_cosine_dists]):\n",
    "#         ppmi_out_of_v_count += 1\n",
    "#     else:\n",
    "    ppmi_cosine_answer = choices[np.argmin(ppmi_cosine_dists)]\n",
    "    if ppmi_cosine_answer == correct_answer:\n",
    "        ppmi_cosine_count += 1\n",
    "    ppmi_euclidean_dists = [ppmi_get_dist(word, candidate, euclidean) for candidate in choices]\n",
    "    ppmi_euclidean_answer = choices[np.argmin(ppmi_euclidean_dists)]\n",
    "    if ppmi_euclidean_answer == correct_answer:\n",
    "        ppmi_euclidean_count += 1\n",
    "\n",
    "# print(\"google's accuracy on the dataset after removing %d questions that contains out-of-vocabulary words:\\\n",
    "#        %.3f using cosine, %.3f using euclidean\"\\\n",
    "#        %(google_out_of_v_count, google_cosine_count / (1000 - google_out_of_v_count),\\\n",
    "#         google_euclidean_count / (1000 - google_out_of_v_count)))\n",
    "# print(\"Classic Approach's accuracy on the dataset after removing %d questions that contains out-of-vocabulary words:\\\n",
    "#        %.3f using cosine, %.3f using euclidean\"\\\n",
    "#        %(ppmi_out_of_v_count, ppmi_cosine_count / (1000 - ppmi_out_of_v_count),\\\n",
    "#         ppmi_euclidean_count / (1000 - ppmi_out_of_v_count)))\n",
    "\n",
    "print(\"Google's accuracy on the dataset:           %.3f using cosine, %.3f using euclidean\"\\\n",
    "       %(google_cosine_count / 1000, google_euclidean_count / 1000))\n",
    "print(\"Classic Approach's accuracy on the dataset: %.3f using cosine, %.3f using euclidean\"\\\n",
    "       %(ppmi_cosine_count / 1000, ppmi_euclidean_count / 1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SAT Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['lull', 'trust'],\n",
       "  ['balk', 'fortitude'],\n",
       "  ['betray', 'loyalty'],\n",
       "  ['cajole', 'compliance'],\n",
       "  ['hinder', 'destination'],\n",
       "  ['soothe', 'passion'],\n",
       "  'c'],\n",
       " [['ostrich', 'bird'],\n",
       "  ['lion', 'cat'],\n",
       "  ['goose', 'flock'],\n",
       "  ['ewe', 'sheep'],\n",
       "  ['cub', 'bear'],\n",
       "  ['primate', 'monkey'],\n",
       "  'a'],\n",
       " [['word', 'language'],\n",
       "  ['paint', 'portrait'],\n",
       "  ['poetry', 'rhythm'],\n",
       "  ['note', 'music'],\n",
       "  ['tale', 'story'],\n",
       "  ['week', 'year'],\n",
       "  'c'],\n",
       " [['coop', 'poultry'],\n",
       "  ['aquarium', 'fish'],\n",
       "  ['forest', 'wildlife'],\n",
       "  ['crib', 'nursery'],\n",
       "  ['fence', 'yard'],\n",
       "  ['barn', 'tool'],\n",
       "  'a'],\n",
       " [['legend', 'map'],\n",
       "  ['subtitle', 'translation'],\n",
       "  ['bar', 'graph'],\n",
       "  ['figure', 'blueprint'],\n",
       "  ['key', 'chart'],\n",
       "  ['footnote', 'information'],\n",
       "  'd']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_questions = []\n",
    "with open(os.path.join('data','SAT-package-V3.txt'), 'r') as f:\n",
    "    content = f.read()\n",
    "    entries = content.split('\\n\\n')[1:]\n",
    "    for entry in entries:\n",
    "        question = [i for i in entry.split('\\n')[1:] if i]\n",
    "        answer = question[-1]\n",
    "        question = [x.split()[:-1] for x in question[:-1]]\n",
    "        question.append(answer)\n",
    "        sat_questions.append(question)\n",
    "\n",
    "sat_questions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I choose to make prediction based on the **cosine similarity of the difference** between each pair of word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(sample1, sample2, word1, word2):\n",
    "    if sample1 not in google_word_dict or sample2 not in google_word_dict:\n",
    "        return np.inf\n",
    "    if word1 not in google_word_dict or word2 not in google_word_dict:\n",
    "        return np.inf\n",
    "    \n",
    "    vec1 = google_vecs[google_word_dict[sample1]] - google_vecs[google_word_dict[sample2]]\n",
    "    vec2 = google_vecs[google_word_dict[word1]] - google_vecs[google_word_dict[word2]]\n",
    "    return cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 115 out of 374 questions including out-of-voc words are passed, 114 out of 259 are answered correctly.\n",
      "Final accuracy is 0.440\n"
     ]
    }
   ],
   "source": [
    "passed_question = 0\n",
    "correct_count = 0\n",
    "for question in sat_questions:\n",
    "    correct_answer = ord(question[-1]) - ord('a')\n",
    "    sample1, sample2 = question[0]\n",
    "    candidates = question[1:-1]\n",
    "    dists = [similarity(sample1, sample2, word1, word2) for word1, word2 in candidates]\n",
    "    if any([x == np.inf for x in dists]):\n",
    "        passed_question += 1\n",
    "        continue\n",
    "    answer = np.argmin(dists)\n",
    "    if answer == correct_answer:\n",
    "        correct_count += 1\n",
    "\n",
    "print(\"With %d out of %d questions including out-of-voc words are passed, %d out of %d are answered correctly.\\nFinal accuracy is %.3f\"\\\n",
    "      %(passed_question, len(sat_questions), correct_count, len(sat_questions) - passed_question,\\\n",
    "        correct_count / (len(sat_questions) - passed_question)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that this accuracy is significantly higher than random guess (0.2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
